{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1RKi14tPKMPg5QPDOD3REPAi8WA-Fm5R4",
      "authorship_tag": "ABX9TyPA8noIppHK6YA73CMbgzVi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aldevand/buzzer-detecction-lstm/blob/main/buzzer_detection_lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import library"
      ],
      "metadata": {
        "id": "ksAskaMfCGPP"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ba51563",
        "outputId": "7235837f-2633-4fcb-989f-09f094aa538a"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install torch\n",
        "!pip install tensorflow\n",
        "!pip install keras\n",
        "!pip install gensim\n",
        "!pip install POT # Mengubah nama library dari 'ot' menjadi 'POT'\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from datetime import timedelta\n",
        "from gensim.models import KeyedVectors\n",
        "from gensim.similarities import WmdSimilarity"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.34.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.9)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.74.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from keras) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras) (0.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from keras) (3.14.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras) (0.17.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.12/dist-packages (from keras) (0.5.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from keras) (25.0)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from optree->keras) (4.15.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.3.0.post1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open>=1.8.1->gensim) (1.17.3)\n",
            "Collecting POT\n",
            "  Downloading POT-0.9.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (34 kB)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.12/dist-packages (from POT) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6 in /usr/local/lib/python3.12/dist-packages (from POT) (1.13.1)\n",
            "Downloading POT-0.9.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (901 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m901.7/901.7 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: POT\n",
            "Successfully installed POT-0.9.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Dataset"
      ],
      "metadata": {
        "id": "OWJNJ0B7Fw25"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel('/content/drive/MyDrive/Keperluan Skripsi/danantara_gabungan.xlsx')"
      ],
      "metadata": {
        "id": "_uhWAZQ7F1Hd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMwUw33HHFzy",
        "outputId": "ad401054-17d9-440d-fe01-86f3c84eaed7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1255 entries, 0 to 1254\n",
            "Data columns (total 15 columns):\n",
            " #   Column                   Non-Null Count  Dtype \n",
            "---  ------                   --------------  ----- \n",
            " 0   conversation_id_str      1255 non-null   int64 \n",
            " 1   created_at               1255 non-null   object\n",
            " 2   favorite_count           1255 non-null   int64 \n",
            " 3   full_text                1255 non-null   object\n",
            " 4   id_str                   1255 non-null   int64 \n",
            " 5   image_url                672 non-null    object\n",
            " 6   in_reply_to_screen_name  112 non-null    object\n",
            " 7   lang                     1255 non-null   object\n",
            " 8   location                 810 non-null    object\n",
            " 9   quote_count              1255 non-null   int64 \n",
            " 10  reply_count              1255 non-null   int64 \n",
            " 11  retweet_count            1255 non-null   int64 \n",
            " 12  tweet_url                1255 non-null   object\n",
            " 13  user_id_str              1255 non-null   int64 \n",
            " 14  username                 1255 non-null   object\n",
            "dtypes: int64(7), object(8)\n",
            "memory usage: 147.2+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head(5))\n",
        "print(df.tail(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "aaobIak9HJS0",
        "outputId": "2bbf5882-2926-4ef5-c53b-26b01576ac14"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   conversation_id_str                      created_at  favorite_count  \\\n",
            "0  1900102038295633920  Thu Mar 13 08:30:02 +0000 2025               2   \n",
            "1  1900122136087585024  Thu Mar 13 09:49:54 +0000 2025               0   \n",
            "2  1900086851337413120  Thu Mar 13 07:29:41 +0000 2025               0   \n",
            "3  1898156438125768960  Fri Mar 07 23:38:55 +0000 2025               1   \n",
            "4  1899762836152155904  Wed Mar 12 10:02:10 +0000 2025               1   \n",
            "\n",
            "                                           full_text               id_str  \\\n",
            "0  Mengacu dari Indonesia Salary Guide 2025 gaji ...  1900102038295633920   \n",
            "1  Electrizen Danantara Indonesia telah resmi dib...  1900122136087585024   \n",
            "2  Wamenkeu Thomas: Danantara Tak Gadai Saham Pem...  1900086851337413120   \n",
            "3  Proyek DME: Mahal &amp; Merugikan! Gasifikasi ...  1898156438125768960   \n",
            "4  Masyarakat Indonesia percaya bahwa BPI Dananta...  1899762836152155904   \n",
            "\n",
            "                                         image_url in_reply_to_screen_name  \\\n",
            "0                                              NaN                     NaN   \n",
            "1  https://pbs.twimg.com/media/Gl6XAlLbYAI-UqI.jpg                     NaN   \n",
            "2                                              NaN                     NaN   \n",
            "3  https://pbs.twimg.com/media/GlebOJZbwAIeiQi.jpg                     NaN   \n",
            "4  https://pbs.twimg.com/media/Gl1QNK1W8AAydDa.jpg                     NaN   \n",
            "\n",
            "  lang                location  quote_count  reply_count  retweet_count  \\\n",
            "0   in               Indonesia            0            0              4   \n",
            "1   in                     NaN            0            0              0   \n",
            "2   in  Jakarta Capital Region            0            0              0   \n",
            "3   in               Indonesia            0            1              2   \n",
            "4   in                 Jakarta            1            1              0   \n",
            "\n",
            "                                           tweet_url          user_id_str  \\\n",
            "0  https://x.com/tempodotco/status/19001020382956...             18129942   \n",
            "1  https://x.com/ImeldaTriS54261/status/190012213...  1849369709390807040   \n",
            "2  https://x.com/cnbcindonesia/status/19000868513...   847372542830444544   \n",
            "3  https://x.com/350Indonesia/status/189815643812...            457187389   \n",
            "4  https://x.com/liputan6dotcom/status/1899762836...             47596019   \n",
            "\n",
            "          username  \n",
            "0       tempodotco  \n",
            "1  ImeldaTriS54261  \n",
            "2    cnbcindonesia  \n",
            "3     350Indonesia  \n",
            "4   liputan6dotcom  \n",
            "      conversation_id_str                      created_at  favorite_count  \\\n",
            "1250  1898963517765820928  Mon Mar 10 05:05:58 +0000 2025               1   \n",
            "1251  1898005540732912128  Fri Mar 07 13:39:18 +0000 2025             372   \n",
            "1252  1899692230496980992  Wed Mar 12 05:21:36 +0000 2025               1   \n",
            "1253  1900068057382608896  Thu Mar 13 06:15:01 +0000 2025               0   \n",
            "1254  1900065026184261888  Thu Mar 13 06:02:58 +0000 2025               0   \n",
            "\n",
            "                                              full_text               id_str  \\\n",
            "1250  Danantara Masuk 10 Besar Badan Investasi Dunia...  1898963517765820928   \n",
            "1251  Bapak Presiden Jenderal TNI (Purn) Prabowo Sub...  1898005540732912128   \n",
            "1252  Mengembangkan Investasi Berbasis Teknologi den...  1899692230496980992   \n",
            "1253  Masyarakat Indonesia percaya bahwa BPI DANANTA...  1900068057382608896   \n",
            "1254  Masyarakat Indonesia percaya bahwa BPI DANANTA...  1900065026184261888   \n",
            "\n",
            "                                            image_url in_reply_to_screen_name  \\\n",
            "1250  https://pbs.twimg.com/media/Glp5QVcbcAAMBft.jpg                     NaN   \n",
            "1251  https://pbs.twimg.com/media/GlcR8fFbwAAT4vZ.jpg                     NaN   \n",
            "1252  https://pbs.twimg.com/media/Gl0QA5maMAAZc9N.jpg                     NaN   \n",
            "1253  https://pbs.twimg.com/media/Gl5l1ByWIAAVckf.jpg                     NaN   \n",
            "1254  https://pbs.twimg.com/media/Gl5jD2EbYAAkY_v.jpg                     NaN   \n",
            "\n",
            "     lang                  location  quote_count  reply_count  retweet_count  \\\n",
            "1250   in         Kota Jambi, Jambi            0            1              0   \n",
            "1251   in                 Indonesia           30          359             39   \n",
            "1252   in                       NaN            0            0              0   \n",
            "1253   in         Tangerang, Banten            0            0              0   \n",
            "1254   in  Bandung Wetan, Indonesia            0            0              0   \n",
            "\n",
            "                                              tweet_url          user_id_str  \\\n",
            "1250  https://x.com/kharism79/status/189896351776582...  1564436564855235072   \n",
            "1251  https://x.com/erickthohir/status/1898005540732...             43088704   \n",
            "1252  https://x.com/pejuang_berkuda/status/189969223...  1645196114453209088   \n",
            "1253  https://x.com/anonymsmee/status/19000680573826...  1533739189124349952   \n",
            "1254  https://x.com/Tivannni/status/1900065026184261840  1686276192352271872   \n",
            "\n",
            "             username  \n",
            "1250        kharism79  \n",
            "1251      erickthohir  \n",
            "1252  pejuang_berkuda  \n",
            "1253       anonymsmee  \n",
            "1254         Tivannni  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Cleaning"
      ],
      "metadata": {
        "id": "WnNu9M06CNhj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fungsi pembersihan teks\n",
        "\n",
        "def cleaning(teks):\n",
        "  teks = teks.lower()\n",
        "  teks = re.sub(r'http\\S+|www\\S+|https\\S+', '', teks, flags=re.MULTILINE)\n",
        "  teks = re.sub(r'@\\w+|#\\w+', '', teks)\n",
        "  teks = re.sub(r'[^a-zA-Z\\s]', '', teks)\n",
        "  tokens = word_tokenize(teks)\n",
        "  list_stopwords = stopwords.words('indonesian')\n",
        "  filtered_tokens = [token for token in tokens if token not in list_stopwords]\n",
        "  teks = ' '.join(filtered_tokens)\n",
        "  return teks\n",
        "# Terapkan fungsi\n",
        "df['teks_bersih'] = df['full_text'].apply(cleaning)\n",
        "print(df[['full_text', 'teks_bersih']].head(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfICdbWCCQ54",
        "outputId": "f7d46218-a950-42b7-ecb4-fbf002e06010"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                           full_text  \\\n",
            "0  Mengacu dari Indonesia Salary Guide 2025 gaji ...   \n",
            "1  Electrizen Danantara Indonesia telah resmi dib...   \n",
            "2  Wamenkeu Thomas: Danantara Tak Gadai Saham Pem...   \n",
            "3  Proyek DME: Mahal &amp; Merugikan! Gasifikasi ...   \n",
            "4  Masyarakat Indonesia percaya bahwa BPI Dananta...   \n",
            "\n",
            "                                         teks_bersih  \n",
            "0  mengacu indonesia salary guide gaji selevel ce...  \n",
            "1  electrizen danantara indonesia resmi dibentuk ...  \n",
            "2   wamenkeu thomas danantara gadai saham pemerintah  \n",
            "3  proyek dme mahal amp merugikan gasifikasi batu...  \n",
            "4  masyarakat indonesia percaya bpi danantara men...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Labeling -> Rule Based"
      ],
      "metadata": {
        "id": "X8uCdtS3iOVS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rule Waktu"
      ],
      "metadata": {
        "id": "wfMZaQO_2WO4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['created_at'] = pd.to_datetime(df['created_at'], utc=True)\n",
        "df.sort_values(by='created_at', inplace=True)\n",
        "df['label_time'] = 0\n",
        "time_threshold = timedelta(minutes=5)\n",
        "for i in range(1, len(df)):\n",
        "    time_diff = df.iloc[i]['created_at'] - df.iloc[i-1]['created_at']\n",
        "    if time_diff <= time_threshold:\n",
        "        df.loc[df.index[i], 'label_time'] = 1\n",
        "        df.loc[df.index[i-1], 'label_time'] = 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7m0FP5aih8Y",
        "outputId": "3068bb99-ffd4-4773-da4a-c70205eb85f5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-741994207.py:1: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df['created_at'] = pd.to_datetime(df['created_at'], utc=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rule Kemiripan Teks"
      ],
      "metadata": {
        "id": "GsJQxFf92bpg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -> unduh GloVe dari lokasi terbaru Menggunakan model GloVe Twitter 27B\n",
        "!wget https://nlp.stanford.edu/data/glove.twitter.27B.zip -O glove_twitter.zip\n",
        "!unzip -q glove_twitter.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x629JbYVrYIm",
        "outputId": "745fa752-cead-4ab5-e043-82fe03f2db10"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-09-06 17:20:51--  https://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.twitter.27B.zip [following]\n",
            "--2025-09-06 17:20:52--  https://downloads.cs.stanford.edu/nlp/data/glove.twitter.27B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1520408563 (1.4G) [application/zip]\n",
            "Saving to: ‘glove_twitter.zip’\n",
            "\n",
            "glove_twitter.zip   100%[===================>]   1.42G  5.00MB/s    in 4m 45s  \n",
            "\n",
            "2025-09-06 17:25:38 (5.09 MB/s) - ‘glove_twitter.zip’ saved [1520408563/1520408563]\n",
            "\n",
            "replace glove.twitter.27B.25d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "glove_file = 'glove.twitter.27B.100d.txt'\n",
        "word_vectors = KeyedVectors.load_word2vec_format(glove_file, binary=False, no_header=True)\n",
        "\n",
        "print(f\"Model Word Embedding Dimuat: {len(word_vectors.index_to_key)} kata, {word_vectors.vector_size} dimensi\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EqS9d5Y2mvZ",
        "outputId": "1999a40c-649a-4b3f-acfc-7d705c45c986"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Word Embedding Dimuat: 1193514 kata, 100 dimensi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bB_4UN9f_PyI",
        "outputId": "ceb0532e-00dc-4df6-80a3-b7a244375a81"
      },
      "source": [
        "texts_tokenized = [doc.split() for doc in df['teks_bersih'].fillna('')]\n",
        "df['label_similarity_wmd'] = 0\n",
        "indices = df.index.to_list()\n",
        "wmd_threshold = 0.5\n",
        "\n",
        "print(f\"Memulai perhitungan dan pelabelan WMD dengan threshold: {wmd_threshold}\")\n",
        "print(f\"Jumlah dokumen: {len(indices)}\")\n",
        "for i in range(len(indices)):\n",
        "    for j in range(i + 1, len(indices)):\n",
        "        doc1_tokens = texts_tokenized[i]\n",
        "        doc2_tokens = texts_tokenized[j]\n",
        "        if doc1_tokens and doc2_tokens:\n",
        "            try:\n",
        "                jarak_wmd = word_vectors.wmdistance(doc1_tokens, doc2_tokens)\n",
        "                if jarak_wmd < wmd_threshold:\n",
        "                    df.loc[indices[i], 'label_similarity_wmd'] = 1\n",
        "                    df.loc[indices[j], 'label_similarity_wmd'] = 1\n",
        "            except Exception as e:\n",
        "                print(f\"Error saat menghitung WMD antara dokumen {indices[i]} dan {indices[j]}: {e}\")\n",
        "print(\"\\nPelabelan berdasarkan WMD selesai.\")\n",
        "print(\"Distribusi Label Kemiripan WMD:\")\n",
        "print(df['label_similarity_wmd'].value_counts())\n",
        "if 1 in df['label_similarity_wmd'].value_counts():\n",
        "    print(\"\\nContoh Dokumen dengan Label Kemiripan WMD = 1:\")\n",
        "    print(df[df['label_similarity_wmd'] == 1][['full_text', 'teks_bersih', 'label_similarity_wmd']].head())\n",
        "else:\n",
        "    print(\"\\nTidak ada dokumen yang diberi label kemiripan WMD = 1.\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memulai perhitungan dan pelabelan WMD dengan threshold: 0.5\n",
            "Jumlah dokumen: 1255\n",
            "\n",
            "Pelabelan berdasarkan WMD selesai.\n",
            "Distribusi Label Kemiripan WMD:\n",
            "label_similarity_wmd\n",
            "1    698\n",
            "0    557\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Contoh Dokumen dengan Label Kemiripan WMD = 1:\n",
            "                                             full_text  \\\n",
            "640  Erick Thohir menyebutkan sedang mempersiapkan ...   \n",
            "652  Menteri BUMN Erick Thohir siapkan kantor untuk...   \n",
            "655  Menteri Badan Usaha Milik Negara (BUMN) Erick ...   \n",
            "651  Menteri BUMN Erick Thohir mendukung kehadiran ...   \n",
            "577  Soal Danantara Ini Jawaban Lugas Menteri BUMN ...   \n",
            "\n",
            "                                           teks_bersih  label_similarity_wmd  \n",
            "640  erick thohir kantor badan pengelola bp investa...                     1  \n",
            "652  menteri bumn erick thohir siapkan kantor badan...                     1  \n",
            "655  menteri badan usaha milik negara bumn erick th...                     1  \n",
            "651  menteri bumn erick thohir mendukung kehadiran ...                     1  \n",
            "577          danantara lugas menteri bumn erick thohir                     1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-> Gabungkan Rule Waktu dan Similarity/Kemiripan"
      ],
      "metadata": {
        "id": "UTSSVa3CSlq-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['label_final'] = 0\n",
        "df.loc[(df['label_time'] == 1) | (df['label_similarity_wmd'] == 1), 'label_final'] = 1\n",
        "print(\"Pelabelan Final Selesai.\")\n",
        "print(\"Distribusi label final:\")\n",
        "print(df['label_final'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSXR8Al6SwYl",
        "outputId": "c12ddc39-8725-42e0-a88f-3da3a02d3c8c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pelabelan Final Selesai.\n",
            "Distribusi label final:\n",
            "label_final\n",
            "1    901\n",
            "0    354\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    }
  ]
}